---
title: VIGIL Risk Intelligence
emoji: üõ°Ô∏è
colorFrom: yellow
colorTo: yellow
sdk: docker
app_file: app.py
app_port: 5000
license: apache-2.0
inference: false
library_name: transformers
pipeline_tag: text-classification
tags:
  - risk-management
  - text-classification
  - risk-detection
  - security
  - machine-learning
  - enterprise
  - dual-source
  - synthesis
  - bert
  - distilbert
  - nlp
  - semantic-search
  - vector-database
  - real-time-alerts
  - grok
  - supabase
  - pgvector
  - flask
  - docker
  - transformers
---

# VIGIL: Enterprise Risk Intelligence System

## Executive Summary

VIGIL is an enterprise-grade risk intelligence platform that transforms how companies detect and respond to business threats. Unlike traditional risk management systems that rely on a single perspective, VIGIL combines two powerful data sources: your company's proprietary historical data and real-time industry knowledge from X.AI's Grok AI. By synthesizing these perspectives with complete attribution and transparency, VIGIL provides risk analysis that is both rooted in your company's proven experience and informed by broader industry patterns.

The system operates by taking natural language queries from business leaders and analyzing them through a dual-path architecture. Your company's private data source provides historical context, proven solutions, and governance rule validation stored in Supabase with pgvector semantic search. Simultaneously, Grok AI provides market analysis, emerging threats, and best practice benchmarking with real-time global knowledge. These findings are merged in a synthesis engine that calculates consensus scores, detects the type of question being asked, and formats responses accordingly. The result is actionable intelligence with clear attribution showing exactly where each finding originated.

VIGIL achieves detection confidence of 95 percent or higher when both sources agree on a risk, and solutions are ranked by their proven effectiveness based on track record. The system responds in under 500 milliseconds per query, uses advanced 768-dimensional semantic embeddings from DistilBERT for accuracy, and stores historical data in Supabase with pgvector support for semantic similarity search. Every recommendation includes confidence levels, evidence from both sources, and implementation guidance. The system includes intelligent alert generation with configurable escalation, format detection for different question types, and comprehensive governance rule checking.

---

## üéØ Overview

VIGIL is a **dual-path risk management transformer** that integrates:

### Path 1: Structured Data Analysis
- PostgreSQL/Supabase for historical risk data
- Vector embeddings with DistilBERT (768-dimensional)
- Semantic similarity search with pgvector
- Structured risk metadata in JSONB format
- Historical pattern matching and correlation analysis

### Path 2: Unstructured Intelligence
- Real-time industry intelligence from Grok AI (X.AI)
- Current market context and situational awareness
- Similar incident research from recent history (last 2 years)
- Industry consensus on risk severity assessment
- Validation and context confirmation from live data

### Interconnected Analysis Engine
Combines both paths to detect:
- **Self-Conflicts:** Contradictions within risk descriptions
- **Historical Precedents:** Similar past incidents with similarity scores (0-100%)
- **Recurring Patterns:** Patterns in specific risk categories
- **Cascading Effects:** How this risk affects other systems and operations
- **Timeline Correlations:** Related risks occurring in same time period
- **Industry Validation:** External market context verification and cross-checking

---

## ‚ú® Core Features

### 1. Intelligent Risk Classification
- **Risk Type Detection:** Product Risk, Service Risk, Brand Risk, Supply Chain, Quality Control
- **Severity Assessment:** Low, Medium, High, Critical
- **Confidence Scoring:** 0-100% confidence in assessment
- **Dynamic Adjustment:** Severity automatically adjusted based on Grok intelligence findings

### 2. Comprehensive Interconnected Risk Analysis

**Self-Conflict Detection**
- Identifies contradictory statements within risk description
- Flags statements like "recovered" vs "still failing"
- Detects inconsistent impact claims

**Historical Precedent Analysis**
- Finds up to 5 most similar past incidents from company history
- Similarity score for each match (0-100%)
- Original severity level and occurrence date
- Timeline comparison

**Pattern Recognition**
- Identifies recurring patterns in specific risk categories
- Frequency analysis across risk types
- Severity distribution in category
- Trend identification

**Cascading Effect Mapping**
- Shows which systems/operations will be affected
- Lists affected risk types and current severity
- Cascade probability estimation (0-100%)
- Secondary risk severity impacts

**Timeline Correlation**
- Groups simultaneously occurring risks
- Related events count in time window
- Configurable time window (default: 14 days)
- Correlation strength scoring (0-100%)

**Industry Intelligence Integration**
- Real-time context search via Grok AI
- Severity validation against industry standards
- Recent similar incidents (last 2 years)
- Resolution methods and outcomes
- Confidence scoring for findings

### 3. Semantic Search
- Vector-based similarity search across all stored risks
- Find related risks by semantic meaning (not just keywords)
- Configurable results (top-1 to top-20)
- Returns similarity scores and full metadata

### 4. Document Management
- Store risk descriptions with comprehensive metadata
- Tag with data source (API, attachment, email, etc.)
- Timestamp all submissions with UTC timestamps
- Track document relationships and references
- Retrieve documents by ID with full history

---

## üèóÔ∏è Architecture

### System Components

1. **DualPathRiskTransformer** - Main transformer combining both analysis paths
   - DistilBERT embedding generation
   - Multi-class risk classification
   - Interconnected analysis orchestration
   - Narrative generation

2. **GrokIntelligenceEngine** - Web intelligence and validation
   - Real-time market research
   - Severity validation against industry standards
   - Similar incident discovery
   - Current context synthesis

3. **RiskCorrelationEngine** - Pattern and correlation detection
   - Self-conflict identification
   - Historical pattern matching
   - Cascading effect analysis
   - Timeline correlation analysis

4. **SchemaValidator** - Input validation and error handling
   - Description length validation (20-5000 chars)
   - Data type checking
   - Required field validation
   - Error reporting

5. **DocumentStore** - Risk document management
   - In-memory document storage
   - Metadata association
   - ID generation and tracking
   - Document retrieval

### Technology Stack

| Component | Technology | Details |
|-----------|-----------|---------|
| Language | Python 3.8+ | Modern async capable |
| ML Framework | PyTorch | GPU/CPU support |
| Embeddings | DistilBERT | 768-dim vectors, fast inference |
| Backend | Flask | Lightweight REST API |
| Database | PostgreSQL | pgvector extension for vectors |
| Vector Search | pgvector | Optimized similarity search |
| External AI | Grok (X.AI) | Real-time intelligence |
| Deployment | Docker | Container orchestration |
| Cloud | Hugging Face Spaces | Serverless deployment |

---

## üìä Data Flow

### Risk Analysis Flow

```
1. USER INPUT
   ‚îú‚îÄ Risk description (text, 20-5000 chars)
   ‚îî‚îÄ Optional metadata (source, category hint)

2. VALIDATION
   ‚îú‚îÄ Length check (min 20, max 5000)
   ‚îú‚îÄ Required fields verification
   ‚îî‚îÄ Error reporting if invalid

3. EMBEDDING GENERATION
   ‚îú‚îÄ Tokenize with DistilBERT tokenizer
   ‚îú‚îÄ Get 768-dimensional embeddings
   ‚îú‚îÄ Store in vector store
   ‚îî‚îÄ Index for semantic search

4. CLASSIFICATION
   ‚îú‚îÄ Category classifier (5 categories)
   ‚îú‚îÄ Severity classifier (4 levels)
   ‚îî‚îÄ Confidence score (0-100%)

5. INTERCONNECTED ANALYSIS (Optional)
   ‚îú‚îÄ Self-conflict detection
   ‚îú‚îÄ Historical pattern matching
   ‚îú‚îÄ Recurring pattern analysis
   ‚îú‚îÄ Grok intelligence gathering
   ‚îú‚îÄ Cascading effect analysis
   ‚îî‚îÄ Timeline correlation

6. SYNTHESIS
   ‚îú‚îÄ Combine all findings
   ‚îú‚îÄ Adjust severity if needed
   ‚îú‚îÄ Generate narrative
   ‚îî‚îÄ Return complete results
```

---

## üöÄ Quick Start

### Requirements

```
python >= 3.8
torch
transformers
flask
flask-cors
supabase
requests
huggingface-hub
```

### Installation

```bash
pip install -r requirements.txt
```

### Configuration

Set environment variables in `.env`:

```
XAI_API_KEY=your_xai_key
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key
FLASK_ENV=development
```

### Running

```bash
python app.py
```

The API will be available at `http://localhost:5000`

---

## üîå API Endpoints

### Health Check
```
GET /api/health
```

Response: System status, component health, timestamp

### Analyze Risk (Full Interconnected Analysis)
```
POST /api/risks/analyze
Content-Type: application/json

{
  "description": "Supply chain disruption affecting Q4 production timeline"
}
```

Response:
- Risk classification (type, severity, confidence)
- Interconnected analysis results
- Historical matches with similarity scores
- Cascading effects mapping
- Industry intelligence findings
- Narrative explanation

### Semantic Search
```
GET /api/risks/search?q=supply+chain&top_k=5
```

Response: Similar risks with similarity scores and metadata

### Get Statistics
```
GET /api/stats
```

Response: Vector store size and embedding statistics

---

## üìÅ Project Files

| File | Purpose | Size |
|------|---------|------|
| main.py | Transformer implementation | 702 lines |
| app.py | Flask REST API | 528 lines |
| .env | Configuration (git protected) | - |
| .gitignore | Security rules | 381 lines |
| push_both.py | Multi-platform push script | - |
| README.md | Documentation | This file |

---

## üîê Security Features

### Credential Protection
- All credentials stored in `.env` (git ignored)
- Environment variables for all sensitive data
- No hardcoded API keys in code
- Tokens entered at runtime only

### Protected Files
```
.env               ‚Üí Git ignored
*.key              ‚Üí Git ignored
*.pem              ‚Üí Git ignored
SUPABASE_*         ‚Üí Git ignored
*_apikey*          ‚Üí Git ignored
*_token*           ‚Üí Git ignored
```

### Token Handling
- HF Token: Entered via secure terminal prompt
- Git Credentials: Stored in Windows Credential Manager
- API Keys: Loaded from environment at runtime
- No token logging or file storage

---

## üìà Performance Characteristics

### Inference Speed
- Embedding generation: ~50ms per risk
- Classification: ~10ms per risk
- Full analysis with Grok: ~500ms-2s per risk

### Scalability
- Vector search: <10ms for 1000 documents
- pgvector support: Millions of vectors
- REST API: Handles concurrent requests

---

## üê≥ Deployment

### Docker
```bash
docker build -t vigil .
docker run -p 5000:5000 vigil
```

### Hugging Face Spaces
```bash
python push_both.py
```

Deploys to:
- Model: https://huggingface.co/YOUR_ORG/dual-path-transformer
- Space: https://huggingface.co/spaces/YOUR_ORG/dual-path-transformer

---

## üë• Development Workflow

### Making Changes
```bash
# Edit files
# Then:
git add .
git commit -m "Your message"
python push_both.py
```

### Git Commands
```bash
git status              # Check status
git log --oneline       # View commits
git remote -v           # View remotes
git checkout .          # Undo changes
git reset --soft HEAD~1 # Undo last commit
```

---

## üìö Key Algorithms

### Text Similarity
- Uses SequenceMatcher for historical matching
- Threshold: 0.6 (60%) for similar incidents
- Returns similarity scores 0-100%

### Vector Embeddings
- DistilBERT: 768-dimensional vectors
- Fast inference and semantic understanding
- Compatible with pgvector

### Severity Adjustment
- Base severity from classifier
- Adjusted if Grok finds "critical"
- Final severity = max(base, grok_severity)

---

## üÜò Troubleshooting

### Common Issues

**"HF_TOKEN not found"**
```powershell
$env:HF_TOKEN = "hf_YOUR_TOKEN"
python push_both.py
```

**"Supabase connection failed"**
- Verify SUPABASE_URL and SUPABASE_KEY
- Check internet connection
- Validate credentials

**"Transformer not loaded"**
- Run: `pip install -r requirements.txt`
- Check disk space (model ~250MB)
- Verify GPU (if using)

---

## üìÑ License

Apache License 2.0

Copyright (c) 2026 CoreSight Group

## üë®‚Äçüíº Author

**Paul Carico**
- CoreSight Group
- VIGIL Risk Intelligence Platform

## ü§ù Support

For questions or issues:
1. Check API endpoint documentation
2. Review .env configuration
3. Test with `/api/health` endpoint
4. Check system requirements
5. Verify all credentials are set

---

**VIGIL: Enterprise Risk Intelligence at Scale** üõ°Ô∏è

Protecting organizations with AI-powered risk detection and mitigation.